import os
import json
import logging
import datetime
import tempfile
import requests

from dotenv import load_dotenv
from telegram import Update, ReplyKeyboardMarkup, ReplyKeyboardRemove
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters
)

import pytesseract
from PIL import Image
from yadisk import YaDisk

# =====================
# –ù–ê–°–¢–†–û–ô–ö–ò
# =====================
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
YADISK_TOKEN = os.getenv("YADISK_TOKEN")
HF_API_TOKEN = os.getenv("HF_API_TOKEN")

ROOT_FOLDER = "MedBot"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

yd = YaDisk(token=YADISK_TOKEN)

# =====================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–û–ï
# =====================
def main_menu():
    return ReplyKeyboardMarkup(
        [
            ["–í—ã–±—Ä–∞—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞", "–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞"],
            ["–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç", "–ù–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã"],
            ["–ó–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"]
        ],
        resize_keyboard=True
    )

def hf_generate(prompt: str) -> str:
    url = "https://router.huggingface.co/models/google/flan-t5-small"
    headers = {
        "Authorization": f"Bearer {HF_API_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "inputs": prompt,
        "parameters": {"max_new_tokens": 256, "temperature": 0.1}
    }
    r = requests.post(url, headers=headers, json=payload, timeout=60)
    r.raise_for_status()
    return r.json()[0]["generated_text"]

def analyze_ocr(text: str) -> dict:
    prompt = f"""
–¢–µ–∫—Å—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞:

{text}

–°–¥–µ–ª–∞–π:
1. –¢–∏–ø –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
2. –î–∞—Ç–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
3. 5 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤

–û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –≤ JSON.
"""
    try:
        return json.loads(hf_generate(prompt))
    except Exception as e:
        logging.error("AI OCR error: %s", e)
        return {"study_type": "–¥–æ–∫—É–º–µ–Ω—Ç", "date": "", "keywords": []}

def get_patients():
    if not yd.exists(ROOT_FOLDER):
        yd.mkdir(ROOT_FOLDER)
        return []
    return [
        item["name"]
        for item in yd.listdir(ROOT_FOLDER)
        if item["type"] == "dir"
    ]

def load_index(patient):
    path = f"{ROOT_FOLDER}/{patient}/index.json"
    if yd.exists(path):
        with tempfile.NamedTemporaryFile(delete=False) as f:
            yd.download(path, f.name)
            return json.load(open(f.name, encoding="utf-8"))
    return []

def save_index(patient, data):
    path = f"{ROOT_FOLDER}/{patient}/index.json"
    with tempfile.NamedTemporaryFile(delete=False, mode="w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
        yd.upload(f.name, path, overwrite=True)

def ocr_file(path):
    try:
        img = Image.open(path)
        return pytesseract.image_to_string(img, lang="rus")
    except Exception as e:
        logging.error("OCR error: %s", e)
        return ""

# =====================
# HANDLERS
# =====================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=main_menu()
    )

async def text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()
    logging.info("TEXT: %s", text)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞
    if context.user_data.get("await_patient_name"):
        patient = text
        path = f"{ROOT_FOLDER}/{patient}"
        if not yd.exists(path):
            yd.mkdir(path)
            save_index(patient, [])
        context.user_data.pop("await_patient_name")
        await update.message.reply_text(
            f"–ü–∞—Ü–∏–µ–Ω—Ç ¬´{patient}¬ª –¥–æ–±–∞–≤–ª–µ–Ω",
            reply_markup=main_menu()
        )
        return

    if text == "–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞":
        context.user_data["await_patient_name"] = True
        await update.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ –∏–º—è –ø–∞—Ü–∏–µ–Ω—Ç–∞:",
            reply_markup=ReplyKeyboardRemove()
        )
        return

    if text == "–í—ã–±—Ä–∞—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞":
        patients = get_patients()
        if not patients:
            await update.message.reply_text("–ü–∞—Ü–∏–µ–Ω—Ç–æ–≤ –Ω–µ—Ç", reply_markup=main_menu())
            return
        await update.message.reply_text(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞:",
            reply_markup=ReplyKeyboardMarkup([[p] for p in patients], resize_keyboard=True)
        )
        return

    if text in get_patients():
        context.user_data["patient"] = text
        await update.message.reply_text(
            f"–í—ã–±—Ä–∞–Ω –ø–∞—Ü–∏–µ–Ω—Ç: {text}",
            reply_markup=main_menu()
        )
        return

    if text == "–ù–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã":
        patient = context.user_data.get("patient")
        if not patient:
            await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞", reply_markup=main_menu())
            return
        docs = load_index(patient)
        if not docs:
            await update.message.reply_text("–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç", reply_markup=main_menu())
            return
        msg = "\n".join(f"‚Ä¢ {d['file']}" for d in docs)
        await update.message.reply_text(f"–î–æ–∫—É–º–µ–Ω—Ç—ã:\n{msg}", reply_markup=main_menu())
        return

    if text == "–ó–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏":
        context.user_data["await_ai_query"] = True
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:", reply_markup=ReplyKeyboardRemove())
        return

    if context.user_data.get("await_ai_query"):
        context.user_data.pop("await_ai_query")
        try:
            answer = hf_generate(text)
            await update.message.reply_text(answer, reply_markup=main_menu())
        except Exception as e:
            await update.message.reply_text("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", reply_markup=main_menu())
        return

    await update.message.reply_text("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞", reply_markup=main_menu())

async def document_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    patient = context.user_data.get("patient")
    if not patient:
        await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞", reply_markup=main_menu())
        return

    doc = update.message.document or update.message.photo[-1]
    file = await doc.get_file()

    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        await file.download_to_drive(tmp.name)
        ocr_text = ocr_file(tmp.name)

    ai = analyze_ocr(ocr_text)
    study = ai.get("study_type", "–¥–æ–∫—É–º–µ–Ω—Ç")
    date = ai.get("date") or datetime.date.today().isoformat()
    keywords = ai.get("keywords", [])[:5]

    filename = f"{patient}-{study}-{date}{os.path.splitext(file.file_path)[1]}"
    remote_folder = f"{ROOT_FOLDER}/{patient}"
    remote_path = f"{remote_folder}/{filename}"

    yd.upload(tmp.name, remote_path, overwrite=True)

    index = load_index(patient)
    index.append({
        "file": filename,
        "study": study,
        "date": date,
        "keywords": keywords
    })
    save_index(patient, index)

    await update.message.reply_text(
        f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω\n\n"
        f"–ù–∞–∑–≤–∞–Ω–∏–µ: {filename}\n"
        f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords)}",
        reply_markup=main_menu()
    )

# =====================
# MAIN
# =====================
if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.Document.ALL | filters.PHOTO, document_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_handler))

    logging.info("Bot started")
    app.run_polling()