import os
import logging
import json
import datetime
import re
import requests

from dotenv import load_dotenv
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

import pytesseract
from yadisk import YaDisk

# ======================
# –ù–ê–°–¢–†–û–ô–ö–ò
# ======================
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
YADISK_TOKEN = os.getenv("YADISK_TOKEN")

ROOT_FOLDER = "MedBot"
LOCAL_TMP = "/tmp"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)

yd = YaDisk(token=YADISK_TOKEN)

DOC_TYPES = [
    "–£–ó–ò",
    "–≠–ö–ì",
    "–≠–≠–ì",
    "–†–µ–Ω—Ç–≥–µ–Ω",
    "–ö–¢",
    "–ú–†–¢",
    "–ê–Ω–∞–ª–∏–∑—ã",
    "–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏",
    "–ë–∏–æ—Ö–∏–º–∏—è –∫—Ä–æ–≤–∏",
    "–ì–æ—Ä–º–æ–Ω—ã",
    "–ú–æ—á–∞",
    "–ö–æ–ø—Ä–æ–≥—Ä–∞–º–º–∞",
    "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ –≤—Ä–∞—á–∞",
    "–í—ã–ø–∏—Å–∫–∞",
    "–°–ø—Ä–∞–≤–∫–∞",
    "–ü—Ä–æ—Ç–æ–∫–æ–ª –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
    "–û—Å–º–æ—Ç—Ä —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞",
    "–ù–∞–∑–Ω–∞—á–µ–Ω–∏—è",
    "–≠–ø–∏–∫—Ä–∏–∑",
    "–î—Ä—É–≥–æ–µ",
]

# ======================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–û–ï
# ======================
def ensure_root():
    if not yd.exists(ROOT_FOLDER):
        yd.mkdir(ROOT_FOLDER)

def get_patients():
    ensure_root()
    return [
        item["name"]
        for item in yd.listdir(ROOT_FOLDER)
        if item["type"] == "dir"
    ]

def extract_date(text: str):
    m = re.search(r"(\d{2}[.\-]\d{2}[.\-]\d{4})", text)
    if m:
        return m.group(1).replace(".", "-")
    return datetime.datetime.now().strftime("%d-%m-%Y")

# ======================
# AI –§–£–ù–ö–¶–ò–ò
# ======================
def ai_detect_doc_type(text: str) -> str:
    url = "https://router.huggingface.co/models/google/flan-t5-base"
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}

    prompt = (
        "–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
        "–û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –æ–¥–Ω–∏–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –∏–∑ —Å–ø–∏—Å–∫–∞:\n"
        + ", ".join(DOC_TYPES)
        + "\n\n–¢–µ–∫—Å—Ç:\n"
        + text[:1500]
        + "\n\n–û—Ç–≤–µ—Ç:"
    )

    try:
        r = requests.post(
            url,
            headers=headers,
            json={"inputs": prompt},
            timeout=40
        )
        r.raise_for_status()
        out = r.json()[0]["generated_text"].strip()

        for t in DOC_TYPES:
            if t.lower() in out.lower():
                return t

        return "–î—Ä—É–≥–æ–µ"

    except Exception as e:
        logging.error("AI type error: %s", e)
        return "–î–æ–∫—É–º–µ–Ω—Ç"

def ai_extract_keywords(text: str):
    url = "https://router.huggingface.co/models/google/flan-t5-base"
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}

    prompt = (
        "–í—ã–¥–µ–ª–∏ 5‚Äì7 –∫–ª—é—á–µ–≤—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤.\n"
        "–¢–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.\n\n"
        + text[:1500]
    )

    try:
        r = requests.post(
            url,
            headers=headers,
            json={"inputs": prompt},
            timeout=40
        )
        r.raise_for_status()
        raw = r.json()[0]["generated_text"]
        return [w.strip().lower() for w in raw.split(",") if len(w.strip()) > 2][:7]

    except Exception as e:
        logging.error("AI keywords error: %s", e)
        return []

# ======================
# OCR
# ======================
def ocr_image(path):
    try:
        return pytesseract.image_to_string(path, lang="rus")
    except Exception as e:
        logging.error("OCR error: %s", e)
        return ""

# ======================
# TELEGRAM HANDLERS
# ======================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    kb = [
        ["–í—ã–±—Ä–∞—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞", "–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞"],
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç", "–ù–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã"],
        ["–ó–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"],
    ]
    await update.message.reply_text(
        "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=ReplyKeyboardMarkup(kb, resize_keyboard=True)
    )

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()

    if text == "–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞":
        context.user_data["await_patient_name"] = True
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –ø–∞—Ü–∏–µ–Ω—Ç–∞:")
        return

    if context.user_data.get("await_patient_name"):
        name = text
        ensure_root()
        yd.mkdir(f"{ROOT_FOLDER}/{name}")
        context.user_data["await_patient_name"] = False
        await update.message.reply_text(f"–ü–∞—Ü–∏–µ–Ω—Ç ¬´{name}¬ª –¥–æ–±–∞–≤–ª–µ–Ω.")
        await start(update, context)
        return

    if text == "–í—ã–±—Ä–∞—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞":
        patients = get_patients()
        if not patients:
            await update.message.reply_text("–ü–∞—Ü–∏–µ–Ω—Ç–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç.")
            return
        await update.message.reply_text(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞:",
            reply_markup=ReplyKeyboardMarkup(
                [[p] for p in patients],
                resize_keyboard=True
            )
        )
        context.user_data["await_select_patient"] = True
        return

    if context.user_data.get("await_select_patient"):
        context.user_data["patient"] = text
        context.user_data["await_select_patient"] = False
        await update.message.reply_text(f"–í—ã–±—Ä–∞–Ω –ø–∞—Ü–∏–µ–Ω—Ç: {text}")
        await start(update, context)
        return

    if text == "–ó–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏":
        context.user_data["await_ai_query"] = True
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:")
        return

    if context.user_data.get("await_ai_query"):
        context.user_data["await_ai_query"] = False
        answer = ai_detect_doc_type(text)
        await update.message.reply_text(f"–û—Ç–≤–µ—Ç:\n{answer}")
        await start(update, context)
        return

    await update.message.reply_text("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞.")

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    patient = context.user_data.get("patient")
    if not patient:
        await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞.")
        return

    doc = update.message.document or update.message.photo[-1]
    file = await doc.get_file()
    local_path = f"{LOCAL_TMP}/{file.file_id}.jpg"
    await file.download_to_drive(local_path)

    logging.info("–§–∞–π–ª —Å–∫–∞—á–∞–Ω: %s", local_path)

    text = ocr_image(local_path)
    doc_type = ai_detect_doc_type(text)
    keywords = ai_extract_keywords(text)
    date = extract_date(text)

    filename = f"{patient}_{doc_type}_{date}.jpg"
    remote_dir = f"{ROOT_FOLDER}/{patient}"
    remote_path = f"{remote_dir}/{filename}"

    if not yd.exists(remote_dir):
        yd.mkdir(remote_dir)

    yd.upload(local_path, remote_path, overwrite=True)

    await update.message.reply_text(
        f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω\n\n"
        f"–ù–∞–∑–≤–∞–Ω–∏–µ: {filename}\n"
        f"–¢–∏–ø: {doc_type}\n"
        f"–î–∞—Ç–∞: {date}\n"
        f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords) if keywords else '–Ω–µ—Ç'}"
    )

    await start(update, context)

# ======================
# MAIN
# ======================
if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.Document.ALL | filters.PHOTO, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    logging.info("Bot started")
    app.run_polling()