import os
import logging
import json
import datetime
import requests
from dotenv import load_dotenv
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
import pytesseract
from yadisk import YaDisk

# ----------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# ----------------------
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
YADISK_TOKEN = os.getenv("YADISK_TOKEN")

ROOT_FOLDER = "MedBot"
DATA_FILE = "patients_data.json"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
yd = YaDisk(token=YADISK_TOKEN)
logging.basicConfig(level=logging.INFO)

# ----------------------
# Helper —Ñ—É–Ω–∫—Ü–∏–∏
# ----------------------
def load_data():
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_data(data):
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def get_embedding(text: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ HF Router API"""
    url = "https://router.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2"
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
    payload = {"inputs": text}
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=30)
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        logging.error("HF embedding error: %s", e)
        return []

def hf_text_gen(prompt: str):
    """HF –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ / –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
    url = "https://api-inference.huggingface.co/models/google/flan-t5-base"
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
    payload = {"inputs": prompt}
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        resp.raise_for_status()
        result = resp.json()
        if isinstance(result, list) and len(result) > 0 and "generated_text" in result[0]:
            return result[0]["generated_text"]
        return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
    except Exception as e:
        logging.error("HF text gen error: %s", e)
        return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"

def ocr_file(file_path):
    try:
        text = pytesseract.image_to_string(file_path, lang="rus")
        return text
    except Exception as e:
        logging.error("OCR error: %s", e)
        return ""

def extract_date(text):
    """–ü—Ä–æ—Å—Ç–µ–π—à–µ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ OCR"""
    import re
    matches = re.findall(r"(\d{2}[./-]\d{2}[./-]\d{4})", text)
    if matches:
        return matches[0].replace("/", "-").replace(".", "-")
    return datetime.datetime.now().strftime("%d-%m-%Y")

def classify_document(text):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"""
    prompt_type = f"–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–≠–ö–ì, –£–ó–ò, –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏, –≠–≠–ì –∏ —Ç.–¥.) –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞: {text[:1000]}"
    doc_type = hf_text_gen(prompt_type).strip()

    prompt_keywords = f"–í—ã–¥–µ–ª–∏ 5‚Äì7 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {text[:1000]}"
    keywords = hf_text_gen(prompt_keywords).strip()
    return doc_type, keywords

# ----------------------
# Handlers
# ----------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    kb = [
        ["–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞", "–í—ã–±—Ä–∞—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞"],
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç", "–ù–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã"],
        ["–ó–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"]
    ]
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=ReplyKeyboardMarkup(kb, resize_keyboard=True)
    )

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()
    data = load_data()

    # –ï—Å–ª–∏ –æ–∂–∏–¥–∞–µ–º —Ñ–∞–π–ª
    if context.user_data.get("awaiting_file"):
        await update.message.reply_text("–û–∂–∏–¥–∞—é —Ñ–∞–π–ª, –∞ –Ω–µ —Ç–µ–∫—Å—Ç.")
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–æ–∫
    if text == "–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞":
        await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –Ω–æ–≤–æ–≥–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞:")
        context.user_data["adding_patient"] = True
        return

    if context.user_data.get("adding_patient"):
        patient_name = text
        if patient_name not in data:
            data[patient_name] = []
            save_data(data)
        context.user_data["adding_patient"] = False
        await update.message.reply_text(f"–ü–∞—Ü–∏–µ–Ω—Ç {patient_name} –¥–æ–±–∞–≤–ª–µ–Ω.")
        await start(update, context)
        return

    if text == "–í—ã–±—Ä–∞—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–∞":
        if not data:
            await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤—å—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞.")
            return
        kb = [[p] for p in data.keys()]
        await update.message.reply_text(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞:",
            reply_markup=ReplyKeyboardMarkup(kb, resize_keyboard=True)
        )
        context.user_data["choosing_patient"] = True
        return

    if context.user_data.get("choosing_patient"):
        if text in data:
            context.user_data["patient"] = text
            context.user_data["choosing_patient"] = False
            await update.message.reply_text(f"–í—ã–±—Ä–∞–Ω –ø–∞—Ü–∏–µ–Ω—Ç {text}")
            await start(update, context)
        else:
            await update.message.reply_text("–ü–∞—Ü–∏–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    if text == "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç":
        if "patient" not in context.user_data:
            await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞!")
            return
        context.user_data["awaiting_file"] = True
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.")
        return

    if text == "–ù–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã":
        if "patient" not in context.user_data:
            await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞!")
            return
        patient = context.user_data["patient"]
        docs = data.get(patient, [])
        if not docs:
            await update.message.reply_text("–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç.")
            return
        msg = "–î–æ–∫—É–º–µ–Ω—Ç—ã:\n"
        for d in docs:
            msg += f"- {d['file_name']}\n"
        await update.message.reply_text(msg)
        return

    if text == "–ó–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏":
        await update.message.reply_text("–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∑–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:")
        context.user_data["awaiting_query"] = True
        return

    if context.user_data.get("awaiting_query"):
        query = text
        response = hf_text_gen(query)
        await update.message.reply_text(f"–û—Ç–≤–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n{response}")
        context.user_data["awaiting_query"] = False
        return

    await update.message.reply_text("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é.")

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if "patient" not in context.user_data:
        await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞!")
        return

    if not context.user_data.get("awaiting_file"):
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É '–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç' –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π —Ñ–∞–π–ª–∞.")
        return

    doc = update.message.document
    file_name = doc.file_name
    patient = context.user_data["patient"]

    new_name = f"{patient}_{file_name}"
    file_path = f"/tmp/{new_name}"
    await doc.get_file().download_to_drive(file_path)
    logging.info(f"–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ: {file_path}")

    text = ocr_file(file_path)
    doc_date = extract_date(text)
    doc_type, keywords = classify_document(text)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    new_name = f"{patient}_{doc_type}_{doc_date}{os.path.splitext(file_name)[1]}"

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫
    remote_folder = f"{ROOT_FOLDER}/{patient}"
    if not yd.exists(remote_folder):
        yd.mkdir(remote_folder)
    remote_path = f"{remote_folder}/{new_name}"
    yd.upload(file_path, remote_path)
    logging.info(f"–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫: {remote_path}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
    data = load_data()
    patient_docs = data.get(patient, [])
    patient_docs.append({
        "file_name": new_name,
        "remote_path": remote_path,
        "text": text,
        "type": doc_type,
        "date": doc_date,
        "keywords": keywords,
    })
    data[patient] = patient_docs
    save_data(data)

    context.user_data["awaiting_file"] = False

    await update.message.reply_text(
        f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω\n\n–ù–∞–∑–≤–∞–Ω–∏–µ: {new_name}\n–¢–∏–ø: {doc_type}\n–î–∞—Ç–∞: {doc_date}\n–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords}"
    )
    await start(update, context)

# ----------------------
# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫
# ----------------------
if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    logging.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    app.run_polling()