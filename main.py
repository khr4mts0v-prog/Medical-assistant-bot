import os
import re
import json
import numpy as np
from datetime import datetime
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler
from yadisk import YaDisk
import pytesseract
from pdf2image import convert_from_path
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from huggingface_hub import InferenceClient

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
BOT_TOKEN = os.environ.get("BOT_TOKEN")
YANDEX_TOKEN = os.environ.get("YANDEX_TOKEN")
HF_API_TOKEN = os.environ.get("HF_API_TOKEN")

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å–µ—Ä–≤–∏—Å–∞–º
y = YaDisk(token=YANDEX_TOKEN)
hf_client = InferenceClient(HF_API_TOKEN)
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # –ª—ë–≥–∫–∞—è –º–æ–¥–µ–ª—å

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

def extract_info_and_generate_name(text, patient_name, original_ext=".pdf"):
    keywords = {"–≠–≠–ì": "eeg", "–∫–∞—Ä–¥–∏–æ–ª–æ–≥–∏—è": "cardiology", "–∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏": "blood_test", "–≠–ö–ì": "ecg"}
    study_type = next((v for k,v in keywords.items() if k.lower() in text.lower()), "other")
    dates = re.findall(r'\b\d{2}[./-]\d{2}[./-]\d{4}\b', text)
    procedure_date = dates[0] if dates else datetime.today().strftime("%Y-%m-%d")
    file_name = f"{patient_name.strip().replace(' ','_').lower()}-{study_type}-{procedure_date}{original_ext}"
    return file_name, study_type, procedure_date

def get_embedding(text):
    return model.encode(text)

def save_document(patient_name, file_path, text):
    ext = os.path.splitext(file_path)[1]
    file_name, study_type, procedure_date = extract_info_and_generate_name(text, patient_name, ext)
    remote_folder = f"/MedicalDocs/{patient_name}"
    if not y.exists(remote_folder):
        y.mkdir(remote_folder)
    remote_path = f"{remote_folder}/{file_name}"
    y.upload(file_path, remote_path, overwrite=True)
    
    embedding = get_embedding(text)
    json_data = {"text": text, "embedding": embedding.tolist(), "original_file": remote_path}
    json_name = file_name + ".json"
    local_json = f"/tmp/{json_name}"
    with open(local_json, "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False)
    y.upload(local_json, f"{remote_folder}/{json_name}", overwrite=True)
    return remote_path

def ocr_from_file(file_path):
    ext = os.path.splitext(file_path)[1].lower()
    text = ""
    if ext == ".pdf":
        pages = convert_from_path(file_path)
        for page in pages:
            text += pytesseract.image_to_string(page, lang='rus')
    else:
        text = pytesseract.image_to_string(file_path, lang='rus')
    return text

def find_docs_in_cloud(patient_name, query, top_n=3):
    folder = f"/MedicalDocs/{patient_name}"
    if not y.exists(folder):
        return []
    files = y.listdir(folder)
    json_files = [f for f in files if f["name"].endswith(".json")]
    docs = []
    for f in json_files:
        local = f"/tmp/{f['name']}"
        y.download(f"{folder}/{f['name']}", local)
        with open(local, "r", encoding="utf-8") as jf:
            doc = json.load(jf)
            docs.append(doc)
    if not docs:
        return []
    query_emb = get_embedding(query)
    sims = [cosine_similarity([query_emb], [np.array(d["embedding"])]).flatten()[0] for d in docs]
    idx = np.argsort(sims)[::-1][:top_n]
    return [docs[i] for i in idx]

def send_docs(update, context, patient_name, docs):
    for doc in docs:
        file_url = doc['original_file']
        local_path = f"/tmp/{os.path.basename(file_url)}"
        y.download(file_url, local_path, overwrite=True)
        context.bot.send_document(chat_id=update.effective_chat.id, document=open(local_path, "rb"))

def ask_hf_model(question, context_text):
    prompt = f"–í–æ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n{context_text}\n\n–í–æ–ø—Ä–æ—Å: {question}\n–û—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ:"
    response = hf_client.text_generation(
        model="tiiuae/falcon-7b-instruct",
        inputs=prompt,
        parameters={"max_new_tokens": 300}
    )
    if isinstance(response, list) and len(response) > 0:
        return response[0]["generated_text"].split("–û—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ:")[-1].strip()
    return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç"

# --- Handlers ---

async def start(update, context):
    context.user_data["current_patient"] = ""
    keyboard = [
        [InlineKeyboardButton("‚ûï –î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã", callback_data='add_doc')],
        [InlineKeyboardButton("üîç –ù–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã", callback_data='find_doc')],
        [InlineKeyboardButton("üß† –ó–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏", callback_data='query')],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –ø–∞—Ü–∏–µ–Ω—Ç–∞ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=reply_markup)

async def set_patient(update, context):
    context.user_data["current_patient"] = update.message.text.strip()
    await update.message.reply_text(f"–ü–∞—Ü–∏–µ–Ω—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {context.user_data['current_patient']}")

async def handle_document(update, context):
    patient_name = context.user_data.get("current_patient", "")
    if not patient_name:
        await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤–≤–µ–¥–∏—Ç–µ –∏–º—è –ø–∞—Ü–∏–µ–Ω—Ç–∞")
        return
    file = await update.message.document.get_file()
    local_path = f"/tmp/{file.file_unique_id}_{update.message.document.file_name}"
    await file.download_to_drive(local_path)
    text = ocr_from_file(local_path)
    remote_path = save_document(patient_name, local_path, text)
    await update.message.reply_text(f"–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {remote_path}")

async def handle_message(update, context):
    text = update.message.text
    patient_name = context.user_data.get("current_patient", "")
    if not patient_name:
        await set_patient(update, context)
        return

    if "–∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã" in text.lower():
        await update.message.reply_text("–û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
        return

    docs = find_docs_in_cloud(patient_name, text)
    if docs:
        combined_text = "\n\n".join([d["text"] for d in docs])
        answer = ask_hf_model(text, combined_text)
        await update.message.reply_text(answer)
        send_docs(update, context, patient_name, docs)
    else:
        await update.message.reply_text("–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")

async def button_handler(update, context):
    query = update.callback_query
    await query.answer()
    if query.data == 'add_doc':
        await query.message.reply_text("–û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
    elif query.data == 'find_doc':
        await query.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    elif query.data == 'query':
        await query.message.reply_text("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
    await query.message.delete()

# --- –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ---
app = ApplicationBuilder().token(BOT_TOKEN).build()
app.add_handler(CommandHandler("start", start))
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
app.add_handler(CallbackQueryHandler(button_handler))

app.run_polling()
